{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chess\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch\")\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/content/sample_data/chessData.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "data = data.sample(3000)\n",
    "print(data.info())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing vals per column:\\n\", data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers beyond a threshold\n",
    "# this code: keep only evaluations within Â±5000 centipawns. maybe double check where we should cut off outliers\n",
    "# data = data[(data['Evaluation'] > -5000) & (data['Evaluation'] < 5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Evaluation'] = pd.to_numeric(data['Evaluation'], errors='coerce')\n",
    "\n",
    "max_eval = data['Evaluation'].max()\n",
    "min_eval = data['Evaluation'].min()\n",
    "\n",
    "print(f\"Maximum Evaluation: {max_eval}\")\n",
    "print(f\"Minimum Evaluation: {min_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Evaluation'], bins=50, kde=True)\n",
    "plt.xlabel('Evaluation')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Evaluation Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_values = data[pd.to_numeric(data['Evaluation'], errors='coerce').isna()]\n",
    "print(\"Non-numeric values in Evaluation column:\")\n",
    "print(non_numeric_values[['Evaluation']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # means forced checkmate, could replace them with a really high positive score?:\n",
    "\n",
    "# Replace '#+X' with a large positive value and '#-X' with a large negative value\n",
    "data['Evaluation'] = data['Evaluation'].replace(\n",
    "    {r'^\\#\\+.*': '10000', r'^\\#\\-.*': '-10000'}, regex=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "non_numeric_values = data[pd.to_numeric(data['Evaluation'], errors='coerce').isna()]\n",
    "print(\"Non-numeric values in Evaluation column:\")\n",
    "print(non_numeric_values[['Evaluation']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNN, then try RELU or sigmoid activation function\n",
    "# first want to convert our data into grids or matrices. might want to convert all the chess pieces into numbers\n",
    "PIECE_TO_INT_2 = {key: i for i, key in enumerate([\"r\", \"n\", \"b\", \"q\", \"k\", \"p\", \"R\", \"N\", \"B\", \"Q\", \"K\", \"P\"])}\n",
    "\n",
    "def fen_to_tensor(fen: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a FEN string into a 3D tensor representation of the board.\n",
    "    Args:\n",
    "        fen (str): Full FEN string.\n",
    "    Returns:\n",
    "        torch.Tensor: 3D tensor with dimensions (12, 8, 8).\n",
    "    \"\"\"\n",
    "    # Extract board layout (first part of FEN)\n",
    "    board_layout = fen.split()[0].strip()\n",
    "\n",
    "    board_tensor = []\n",
    "    for piece in PIECE_TO_INT_2.keys():  # Going through every piece type\n",
    "        piece_matrix = []\n",
    "        for row in board_layout.split(\"/\"):  # Split the FEN into rows\n",
    "            row_vec = []\n",
    "            for element in row:  # Check each piece in the row\n",
    "                if element.isalpha():  # If it's a piece\n",
    "                    row_vec.append(1 if element == piece else 0)\n",
    "                elif element.isdigit():  # If it's a number (of empty squares)\n",
    "                    row_vec.extend([0] * int(element))\n",
    "                else:\n",
    "                    raise ValueError(f\"Invalid FEN character: {element}\")\n",
    "            # Ensure 8 columns per row\n",
    "            assert len(row_vec) == 8, f\"Row length mismatch: {row_vec}\"\n",
    "            piece_matrix.append(row_vec)\n",
    "\n",
    "        # Ensure 8 rows per piece\n",
    "        assert len(piece_matrix) == 8, f\"Matrix size mismatch for piece {piece}\"\n",
    "        board_tensor.append(piece_matrix)\n",
    "\n",
    "    # Ensure 12 slices (one for each piece type)\n",
    "    assert len(board_tensor) == 12, \"Board tensor size mismatch\"\n",
    "\n",
    "    return torch.tensor(board_tensor, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# ! pip install torchvision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from itertools import islice\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the data through transformation first\n",
    "# can make a custom dataset\n",
    "from torch.utils.data import Dataset\n",
    "# from FEN_to_vector import to_vector\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): The DataFrame containing the FEN strings and target evaluations.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the FEN string and target evaluation\n",
    "        fen = self.dataframe.iloc[idx]['FEN']\n",
    "        evaluation = self.dataframe.iloc[idx]['Evaluation']\n",
    "\n",
    "        board_vector = fen_to_tensor(fen)\n",
    "\n",
    "\n",
    "        # Convert FEN to tensor\n",
    "        board_tensor = board_vector.clone().detach()\n",
    "\n",
    "        return board_tensor, torch.tensor(float(evaluation), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portioned_train_data = train_data.sample(frac=0.3, random_state=42)\n",
    "portioned_val_data = val_data.sample(frac=0.3, random_state=42)\n",
    "portioned_test_data = test_data.sample(frac=0.3, random_state=42)\n",
    "\n",
    "train_dataset = ChessDataset(portioned_train_data)\n",
    "val_dataset = ChessDataset(portioned_val_data)\n",
    "test_dataset = ChessDataset(portioned_test_data)\n",
    "\n",
    "batch = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = len(train_loader)\n",
    "\n",
    "print(f\"Total number of batches: {num_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple chess CNN\n",
    "class ChessNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(12, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 4 * 4, 1)  # Simplified fully connected layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure the input has the right shape for Conv2d\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(0)\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for me because I have a macbook :'(\n",
    "# device = torch.device(\"cuda\" if torch.backends.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   print(\"Training on GPU\")\n",
    "   device = torch.device(\"cuda:0\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model = ChessNN().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001) # initial learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_limit = 10  # only process 10 batches\n",
    "\n",
    "model.eval()\n",
    "val_predictions_before = []\n",
    "val_targets_before = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (board_tensors, targets) in enumerate(val_loader):\n",
    "        if i >= batch_limit:\n",
    "            break  # Stop after processing 'batch_limit' batches\n",
    "\n",
    "        board_tensors, targets = board_tensors.to(device), targets.to(device)\n",
    "        outputs = model(board_tensors)\n",
    "\n",
    "        val_predictions_before.extend(outputs.squeeze().cpu().numpy())  # Store predictions\n",
    "        val_targets_before.extend(targets.cpu().numpy())  # Store true targets\n",
    "\n",
    "# Compute Mean Squared Error before training\n",
    "mse_val_before = mean_squared_error(val_targets_before, val_predictions_before)\n",
    "print(f\"MSE before training: {mse_val_before:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 600\n",
    "batch_limit = 50\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, (board_tensors, targets) in enumerate(train_loader):\n",
    "        if i >= batch_limit:  # Stop after processing a limited number of batches\n",
    "            break\n",
    "\n",
    "        board_tensors, targets = board_tensors.to(device), targets.to(device)\n",
    "\n",
    "        if board_tensors.dim() == 3:\n",
    "            board_tensors = board_tensors.unsqueeze(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        predictions = model(board_tensors)\n",
    "        loss = loss_fn(predictions.squeeze(), targets)\n",
    "\n",
    "        # Backward pass\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    losses.append(total_loss / batch_limit)\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / (batch_limit):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss', color='tab:blue')\n",
    "ax1.plot(range(epochs), losses, color='tab:blue', label='Loss')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "\n",
    "plt.title('Loss over Training Epochs')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_predictions = []\n",
    "val_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (board_tensors, targets) in enumerate(val_loader):\n",
    "        if i >= batch_limit:\n",
    "            break  # Stop after processing 'batch_limit' batches\n",
    "\n",
    "        board_tensors, targets = board_tensors.to(device), targets.to(device)\n",
    "        outputs = model(board_tensors)\n",
    "\n",
    "        val_predictions.extend(outputs.squeeze().cpu().numpy())  # Store predictions\n",
    "        val_targets.extend(targets.cpu().numpy())  # Store true targets\n",
    "\n",
    "# Compute Mean Squared Error after evaluation\n",
    "mse_val = mean_squared_error(val_targets, val_predictions)\n",
    "print(f\"Validation MSE: {mse_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "val_loss = 0\n",
    "\n",
    "with torch.no_grad():  # No gradients are calculated during evaluation\n",
    "    for i, (board_tensors, targets) in enumerate(val_loader):\n",
    "        if i >= batch_limit:\n",
    "            break\n",
    "\n",
    "        board_tensors, targets = board_tensors.to(device), targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(board_tensors)\n",
    "        loss = loss_fn(predictions.squeeze(), targets)\n",
    "        val_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "print(f\"Validation Loss: {val_loss / batch_limit:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math156",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
